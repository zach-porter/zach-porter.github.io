[
  {
    "title": "Lingo Telecom settles with FCC paying $1 million in civil penalties Over Deepfake Robocalls Featuring President Biden",
    "intro": "Earlier this year, Steve Kramer, a political consultant, was hired by the campaign of Dean Phillips, who himself was a Democratic congressman from Minnesota challenging Biden for the party's presidential nomination. After receiving this job, Kramer utilized AI to create robocalls that mimicked President Biden’s voice. This was one of the first large-scale political cases of deepfakes in the U.S. The wireless provider Texas-based Lingo Telecom has settled with the Federal Communications Commission (FCC) over its role in transmitting the AI-generated robocalls. The calls were aimed at potential voters in New Hampshire during the state's Democratic primaries, with the intent of misleading voters into thinking Biden and his campaign did not want their support. As part of the settlement, Lingo Telecom will pay a $1 million civil penalty and implement stricter controls to prevent similar incidents in the future. It is important to note that despite the campaign of deepfake robocalls, the tactic proved ineffective in hurting Biden in that New Hampshire primary. Dean Phillips garnered less than 20% of the vote in New Hampshire, while President Biden secured nearly 64%. ",
    "sections": [
      {
        "heading": "Lingo Telecom’s Role and FCC Violation",
        "content": "Although Lingo Telecom did not create the robocalls, it allowed them to be transmitted over its network, violating FCC regulations. The FCC’s “Know Your Customer” (KYC) and “Know Your Upstream Provider” (KYUP) rules require telecom companies to verify the identity and intent of their customers to prevent the misuse of their networks for fraudulent or malicious purposes. Lingo’s failure to adequately vet the robocalls and their origins led to the FCC’s enforcement action.“The misuse of generative AI voice-cloning technology and caller ID spoofing over the U.S. communications network presents a significant threat,” said Loyaan A. Egal, chief of the FCC’s enforcement bureau. “This settlement sends a strong message that communications service providers are the first line of defense against these threats and will be held accountable to ensure they do their part to protect the American public.”"
      },
      {
        "heading": "FCC’s Stance on AI and Voter Trust",
        "content": "FCC Chairwoman Jessica Rosenworcel underscored the importance of trust in communications, especially in the context of elections. “Every one of us deserves to know that the voice on the line is exactly who they claim to be,” she said. “If AI is being used, that should be made clear to any consumer, citizen, and voter who encounters it. The FCC will act when trust in our communications networks is on the line. The settlement with Lingo Telecom is a step towards reinforcing that trust. Alongside the financial penalty, Lingo has agreed to implement several measures. 1) A-Level Attestation: Lingo will apply the highest level of trust only to calls where it has provided the caller ID number to the caller. 2) Verification of Customers and Providers: the company will verify the identity and business line of each customer and upstream provider by obtaining independent corroborating records. 3) Robocall Mitigation: Lingo will transmit traffic only from upstream providers with robust robocall mitigation mechanisms and responsiveness to traceback requests. Hopefully this means less spam and robocalls in general, as other companies may follow suit in order to avoid having to pay for the public scandals. $1 million is quite a low penalty for a company's part in voter misinformation, and thus the penalty in and of itself probably won’t scare other wireless providers. This ruling on the use of deepfake technology in political campaigns represents the role the FCC and other federal agencies have in regulating AI. While the Phillips campaign disavowed any knowledge of Kramer’s actions, the incident proves how easily AI-generated content can be misused to influence voters and undermine democratic processes. As seen on platform X, formerly known as Twitter, plenty of misinformation has been spreading over the election, with Elon Musk spreading misleading information. The FCC has framed the issue in the broader context of national security, warning of the potential for both domestic operatives and foreign adversaries to exploit generative AI and caller ID spoofing for election interference. Recently, OpenAI has released information on how they stopped an Iranian covert information operation regarding the presidential election. These incidents highlight the need for stricter regulations and oversight of AI, social media, and even wireless providers to protect elections. As AI continues to evolve, the importance of maintaining transparency and trust in the spread of information, whether in social networks or through robocalls, becomes even more vital. The settlement with Lingo Telecom is a first small step in addressing the misuse of AI for political manipulation, but it also demonstrates the need for ongoing regulation and preparedness for how AI is already affecting our lives, socially, politically, and personally. By holding service providers accountable, the FCC is reinforcing the principle that trust in communication is fundamental to the democratic process. However, will other agencies be as stringent on the large tech companies, such as X, OpenAI, Google, when their products are the ones at the heart of the deepfakes? I think all of these companies can survive a $1 million penalty, but can they handle some of the scandal? As demonstrated by X’s faced change to their models output, the scandal can be quite effective. However, how much damage will the misinformation do to individuals and the U.S. election before agencies and governments put regulation in place? Will these regulations only apply to U.S. elections, or will the U.S. enforce laws so that the U.S. AI tech companies services cannot be used in other countries' elections as well? "
      }
    ],
    "image": "https://zach-porter.github.io/assets/blog-image-6.webp"
  },
{
  "title": "The Newly Released AI Risk Repository",
  "intro": "A New Framework for Discussing and Navigating AI's Risk and Safety Measures",
  "content": "<p>Full content of the post goes here...</p>",
  "image": "https://zach-porter.github.io/assets/Blog3.jpeg"
},
{
  "title": "The AI Agents Learning to Hack",
  "intro": "New Research from this year: training AI Agents to Hack and defending against Hacking",
  "content": "<p>Full content of the post goes here...</p>",
  "image": "https://zach-porter.github.io/assets/Blog2.jpeg"
}
]
  